{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2170465,"sourceType":"datasetVersion","datasetId":1165452}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **1. Veri İşleme** #","metadata":{}},{"cell_type":"markdown","source":"# - Kütüphaneler #","metadata":{}},{"cell_type":"markdown","source":"Projede kullanılacak kütüphanelerin dahil edilmesi.","metadata":{}},{"cell_type":"code","source":"# Gerekli kütüphaneleri yüklüyoruz\nimport numpy as np  # Sayısal hesaplamalar için NumPy kütüphanesini içe aktarıyoruz\nimport pandas as pd  # Veri analizi ve manipülasyonu için Pandas kütüphanesini içe aktarıyoruz\nimport matplotlib.pyplot as plt  # Görselleştirme için Matplotlib kütüphanesini içe aktarıyoruz\nfrom sklearn.model_selection import train_test_split  # Veri setini eğitim ve test olarak ayırmak için fonksiyonu içe aktarıyoruz\nfrom keras.preprocessing.image import load_img, img_to_array  # Görüntü işleme için gerekli fonksiyonları içe aktarıyoruz\nfrom tqdm import tqdm  # İlerleme çubuğu oluşturmak için kütüphaneyi içe aktarıyoruz\nimport seaborn as sns  # Gelişmiş veri görselleştirme için Seaborn kütüphanesini yüklüyoruz\nfrom sklearn.metrics import classification_report, confusion_matrix  # Model performansını değerlendirmek için metrikleri içe aktarıyoruz\nimport tensorflow as tf  # TensorFlow kütüphanesini içe aktarıyoruz\nimport os  # İşletim sistemi ile etkileşim için os kütüphanesini içe aktarıyoruz\nfrom tensorflow.keras.models import Sequential  # Model oluşturmak için Sequential sınıfını içe aktarıyoruz\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # CNN katmanlarını içe aktarıyoruz\nfrom tensorflow.keras.optimizers import Adam  # Adam optimizasyon algoritmasını içe aktarıyoruz\nimport warnings  # Uyarı yönetimi için warnings kütüphanesini içe aktarıyoruz\n\nwarnings.filterwarnings(\"ignore\")  # Uyarıları gizlemek için kullanıyoruz","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T10:11:58.498211Z","iopub.execute_input":"2024-10-24T10:11:58.498627Z","iopub.status.idle":"2024-10-24T10:11:58.506556Z","shell.execute_reply.started":"2024-10-24T10:11:58.498589Z","shell.execute_reply":"2024-10-24T10:11:58.505418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# - Veri setini Tanımlama #","metadata":{}},{"cell_type":"markdown","source":"Verilerin okunması ve data_directory'e aktarılması.","metadata":{}},{"cell_type":"code","source":"# Resim dosyalarının bulunduğu ana dizin\ndata_directory = '//kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset'\n\n# Bu dizindeki alt klasörler (balık sınıfları) alınıyor. '.' içermeyen klasörler sınıf isimleridir.\nfish_classes = [folder for folder in os.listdir(data_directory) if '.' not in folder]\nfish_classes  # Bulunan balık türlerini listele","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.508553Z","iopub.execute_input":"2024-10-24T10:11:58.509381Z","iopub.status.idle":"2024-10-24T10:11:58.529498Z","shell.execute_reply.started":"2024-10-24T10:11:58.509335Z","shell.execute_reply":"2024-10-24T10:11:58.528630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Resim dosyalarının yolları ve etiketleri için başlangıçta boş listeler oluşturuluyor\nimage_labels = []  # Resim etiketleri için liste\nfile_paths = []  # Resim dosya yolları için liste\n\n# Belirtilen dizindeki dosya yapısını gezerek işlemler yapıyoruz\nfor directory, _, files in os.walk(data_directory):\n    for file in files:\n        # Sadece '.png' uzantılı dosyaları işleme alıyoruz\n        if file.endswith('.png'):\n            # Eğer 'GT' (ground truth) klasöründe değilse etiketi al\n            if 'GT' not in os.path.basename(directory):            \n                image_labels.append(os.path.basename(directory))  # Klasör ismini etiketi olarak ekle\n                file_paths.append(os.path.join(directory, file))  # Dosya yolunu listeye ekle\n\n# Elde edilen resim yolları ve etiketler ile bir DataFrame oluşturuyoruz\ndataset = pd.DataFrame(columns=['path', 'label'])  # Boş bir DataFrame oluştur\ndataset['path'] = file_paths  # Resim yollarını ekliyoruz\ndataset['label'] = image_labels  # Etiketleri ekliyoruz","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.530757Z","iopub.execute_input":"2024-10-24T10:11:58.531312Z","iopub.status.idle":"2024-10-24T10:11:58.645165Z","shell.execute_reply.started":"2024-10-24T10:11:58.531271Z","shell.execute_reply":"2024-10-24T10:11:58.644487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.646811Z","iopub.execute_input":"2024-10-24T10:11:58.647094Z","iopub.status.idle":"2024-10-24T10:11:58.657224Z","shell.execute_reply.started":"2024-10-24T10:11:58.647063Z","shell.execute_reply":"2024-10-24T10:11:58.656398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# - Birkaç Satır ve Temel Bilgileri Gösterme #","metadata":{}},{"cell_type":"code","source":"# İlk resim yolunu görüntülüyoruz (index 0'daki)\nfirst_image_path = dataset.path.iloc[0]  # .iloc kullanarak ilk resim yolunu alıyoruz\nfirst_image_path","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.658458Z","iopub.execute_input":"2024-10-24T10:11:58.659217Z","iopub.status.idle":"2024-10-24T10:11:58.669584Z","shell.execute_reply.started":"2024-10-24T10:11:58.659184Z","shell.execute_reply":"2024-10-24T10:11:58.668738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Veri setinin yapısına göz atalım\nprint(dataset.info())\n\n# Veri setinden örnek satırlar görüntüleyerek genel yapısına dair bir fikir edinelim\nsample_data = dataset.head()  # İlk 5 satırı seçiyoruz\nprint(sample_data)\n\n# Her balık sınıfının veri setindeki sayısını belirleyelim\n# Bu, her etiketin ne kadar temsil edildiğini anlamamıza yardımcı olur\nfish_class_distribution = dataset['label'].value_counts()\nprint(\"Numbers of fish classes:\\n\", fish_class_distribution)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.670654Z","iopub.execute_input":"2024-10-24T10:11:58.670948Z","iopub.status.idle":"2024-10-24T10:11:58.691493Z","shell.execute_reply.started":"2024-10-24T10:11:58.670918Z","shell.execute_reply":"2024-10-24T10:11:58.690566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# - Veri Görselleştirme #","metadata":{}},{"cell_type":"markdown","source":"Veri setindeki türlerin dağılımı görsel olarak sınıflandırılmıştır.","metadata":{}},{"cell_type":"code","source":"# Balık türlerinin dağılımını görsel olarak inceleyelim\nplt.figure(figsize=(12, 8))  # Görüntü boyutunu ayarlıyoruz\nsns.countplot(data=dataset, x='label', palette='Spectral')  # Çubuk grafikle sınıf sayılarını gösteriyoruz\nplt.title('Fish Species Class Distribution', fontsize=16, fontweight='bold')  # Grafik başlığını kalın yapıyoruz\nplt.xlabel('Fish Species', fontsize=12)  # X eksenine etiket ekliyoruz\nplt.ylabel('Number', fontsize=12)  # Y eksenine etiket ekliyoruz\nplt.xticks(rotation=30, ha='right', fontsize=10)  # X eksenindeki etiketleri döndürerek hizalıyoruz\nplt.yticks(fontsize=10)  # Y ekseni etiket boyutunu ayarlıyoruz\nplt.grid(axis='y', linestyle='--', alpha=0.7)  # Y eksenine kılavuz çizgileri ekliyoruz\nplt.tight_layout()  # Grafik düzenini iyileştiriyoruz\nplt.show()  # Grafiği ekranda gösteriyoruz","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.692642Z","iopub.execute_input":"2024-10-24T10:11:58.693182Z","iopub.status.idle":"2024-10-24T10:11:58.984761Z","shell.execute_reply.started":"2024-10-24T10:11:58.693139Z","shell.execute_reply":"2024-10-24T10:11:58.983867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Her sınıftan birkaç örnek gösterme.","metadata":{}},{"cell_type":"code","source":"# Her sınıftan birkaç örnek görüntüyü görselleştirelim\nplt.figure(figsize=(24, 24))  # Grafik boyutunu ayarlıyoruz\n# İlk 9 balık sınıfını gösterecek şekilde döngü oluşturuyoruz\nfor i, label in enumerate(dataset['label'].unique()[:9]):  \n    plt.subplot(4, 3, i + 1)  # 4x3'lük alt grafik oluşturuyoruz\n    # İlgili sınıfa ait ilk görüntüyü yüklüyoruz\n    image_path = dataset[dataset['label'] == label].iloc[0, 0]  \n    img = plt.imread(image_path)\n    plt.imshow(img)  # Resmi yüklüyoruz\n    plt.title(label, fontsize=18, fontweight='bold')  # Sınıf adını başlık olarak ekliyoruz\n    plt.axis('off')  # Eksenleri kapatıyoruz\n\nplt.suptitle('Sample Images of Fish Species', fontsize=20, fontweight='bold')  # Üst başlık ekliyoruz\nplt.tight_layout(rect=[0, 0, 1, 0.95])  # Alt grafiklerin düzenini iyileştiriyoruz\nplt.show()  # Grafiği gösteriyoruz","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:11:58.987875Z","iopub.execute_input":"2024-10-24T10:11:58.988555Z","iopub.status.idle":"2024-10-24T10:12:02.840163Z","shell.execute_reply.started":"2024-10-24T10:11:58.988505Z","shell.execute_reply":"2024-10-24T10:12:02.838828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **2. Model** #","metadata":{}},{"cell_type":"code","source":"# Veri setini eğitim ve test olarak ayırıyoruz.\ntrain_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42, stratify=dataset['label'])\n\ndef load_and_preprocess_image(image_path, target_size=(224, 224)):\n    try:\n        img = load_img(image_path, target_size=target_size)  # Görüntüyü belirtilen boyutta yüklüyoruz\n        img_array = img_to_array(img)  # Görüntüyü dizi formatına çeviriyoruz\n        return img_array / 255.0  # Piksel değerlerini normalize ediyoruz\n    except Exception as e:\n        print(f\"Error: {e}. {image_path} could not be loaded.\")\n        return None #Hata durumunda mesaj göster\n\n# Eğitim verileri için X_train ve y_train hazırlıyoruz\nX_train = np.array([img for img in (load_and_preprocess_image(path) for path in tqdm(train_set['path'], desc=\"Loading Training Images\")) if img is not None])\ny_train = pd.get_dummies(train_set['label']).values  # Etiketleri one-hot encoding ile dönüştürüyoruz\n\n# Test verileri için X_test ve y_test hazırlıyoruz\nX_test = np.array([img for img in (load_and_preprocess_image(path) for path in tqdm(test_set['path'], desc=\"Loading Test Images\")) if img is not None])\ny_test = pd.get_dummies(test_set['label']).values  # Test etiketlerini one-hot encoding ile dönüştürüyoruz\n\n# Eğitim ve test setlerinin boyutlarını yazdırıyoruz\nprint(\"Training set size:\", X_train.shape)\nprint(\"Test set size:\", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:12:02.841799Z","iopub.execute_input":"2024-10-24T10:12:02.842181Z","iopub.status.idle":"2024-10-24T10:13:30.990753Z","shell.execute_reply.started":"2024-10-24T10:12:02.842140Z","shell.execute_reply":"2024-10-24T10:13:30.989839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Modelin Tanımlanması** #","metadata":{}},{"cell_type":"code","source":"# Model oluşturma\nmodel = Sequential()\n\n# İlk Convolutional Katman\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(2, 2))\n\n# İkinci Convolutional Katman\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(2, 2))\n\n# Üçüncü Convolutional Katman\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(2, 2))\n\n# Flatten Katmanı\nmodel.add(Flatten())\n\n# Tam Bağlantılı Katmanlar\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Çıkış Katmanı (Sınıf sayısına göre)\nmodel.add(Dense(9, activation='softmax'))  # Sınıf sayısı dataset'e göre ayarlanmış\n\n# Modeli derlemek\nmodel.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Model özeti\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:13:30.992029Z","iopub.execute_input":"2024-10-24T10:13:30.992418Z","iopub.status.idle":"2024-10-24T10:13:31.137127Z","shell.execute_reply.started":"2024-10-24T10:13:30.992375Z","shell.execute_reply":"2024-10-24T10:13:31.136303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **4. Modelin Eğitilmesi ve Geliştirilmesi**  #","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Model eğitimi\nhistory = model.fit(\n    X_train,                # Eğitim verileri\n    y_train,                # Eğitim etiketleri\n    epochs=20,              # Eğitim döngü sayısı (20 epoch ile başlatılıyor)\n    batch_size=32,          # Her iterasyonda işlenecek görüntü sayısı\n    validation_split=0.2,   # Eğitim verilerinin %20'si doğrulama için ayrılacak\n    callbacks=[early_stopping]  # Erken durdurma ile aşırı öğrenmeyi engelleme\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:13:31.138315Z","iopub.execute_input":"2024-10-24T10:13:31.138597Z","iopub.status.idle":"2024-10-24T10:16:43.101605Z","shell.execute_reply.started":"2024-10-24T10:13:31.138566Z","shell.execute_reply":"2024-10-24T10:16:43.100749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# - Accuracy ve Loss Grafiği #","metadata":{}},{"cell_type":"markdown","source":"Eğitim kayıplarını ve doğruluğu görselleştirelim ","metadata":{}},{"cell_type":"code","source":"# Kayıp (Loss) grafiği\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Loss Graph')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Doğruluk (Accuracy) grafiği\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Accuracy Graph')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:16:43.103077Z","iopub.execute_input":"2024-10-24T10:16:43.103392Z","iopub.status.idle":"2024-10-24T10:16:43.686758Z","shell.execute_reply.started":"2024-10-24T10:16:43.103359Z","shell.execute_reply":"2024-10-24T10:16:43.685759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# - Modelin Değerlendirilmesi #","metadata":{}},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(X_test, y_test)\nprint(f'Test Loss: {test_loss:.4f}')\nprint(f'Test Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:16:43.688377Z","iopub.execute_input":"2024-10-24T10:16:43.688821Z","iopub.status.idle":"2024-10-24T10:16:48.924874Z","shell.execute_reply.started":"2024-10-24T10:16:43.688773Z","shell.execute_reply":"2024-10-24T10:16:48.923949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modelin test verileri üzerindeki tahminleri\ny_pred_probs = model.predict(X_test)  # Tahmin edilen olasılıklar\ny_pred_classes = np.argmax(y_pred_probs, axis=1)  # En yüksek olasılığa sahip sınıfı seçiyoruz\n\n# Gerçek sınıfları elde ediyoruz\ny_true_classes = np.argmax(y_test, axis=1)  # One-hot encoding'den orijinal sınıf etiketlerine dönüştürüyoruz","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:16:48.926292Z","iopub.execute_input":"2024-10-24T10:16:48.926787Z","iopub.status.idle":"2024-10-24T10:16:52.603309Z","shell.execute_reply.started":"2024-10-24T10:16:48.926739Z","shell.execute_reply":"2024-10-24T10:16:52.602453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Sınıflandırma raporu\nprint(classification_report(y_true_classes, y_pred_classes, target_names=dataset['label'].unique()))","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:16:52.604506Z","iopub.execute_input":"2024-10-24T10:16:52.604851Z","iopub.status.idle":"2024-10-24T10:16:52.620972Z","shell.execute_reply.started":"2024-10-24T10:16:52.604818Z","shell.execute_reply":"2024-10-24T10:16:52.619989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Karışıklık matrisi\ncm = confusion_matrix(y_true_classes, y_pred_classes)\n\n# Karışıklık matrisini görselleştirme\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=dataset['label'].unique(), yticklabels=dataset['label'].unique())\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:16:52.622241Z","iopub.execute_input":"2024-10-24T10:16:52.622526Z","iopub.status.idle":"2024-10-24T10:16:53.190050Z","shell.execute_reply.started":"2024-10-24T10:16:52.622495Z","shell.execute_reply":"2024-10-24T10:16:53.189018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **5. Veri Setindeki Görüntüyü Sınıflandırma ve Tahmin İşlemi** #","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Örnek bir resim yükleme (Pillow ile)\nimage_path = '/kaggle/input/a-large-scale-fish-dataset/Fish_Dataset/Fish_Dataset/Hourse Mackerel/Hourse Mackerel/00030.png'\n\n# Görüntüyü Pillow ile aç, boyutlandır ve normalize et\ntest_img = Image.open(image_path)  # Görüntüyü aç\ntest_img = test_img.resize((224, 224))  # Modelin beklediği boyut (224x224) olacak şekilde yeniden boyutlandır\ntest_img_array = np.array(test_img).astype('float32') / 255  # NumPy dizisine dönüştür ve normalize et\n\n# Modelin beklediği formatta giriş oluşturmak için boyutları genişlet\ntest_img_array = np.expand_dims(test_img_array, axis=0)  # (1, 224, 224, 3) boyutuna genişlet\n\n# Modelden tahmin yapma\npredictions = model.predict(test_img_array)\n\n# Tahmin edilen sınıf indeksini bulma\npredicted_class_index = np.argmax(predictions)\n\n# Dataset içindeki etiket isimlerini alıyoruz\nclass_names = dataset['label'].unique()  # Sınıf isimlerini elde ediyoruz\n\n# Tahmin edilen sınıf ismi\npredicted_class = class_names[predicted_class_index]\n\n# Tahmin sonucunu görselleştirme (Pillow ile)\nplt.imshow(test_img)  # test_img PIL imaj nesnesidir, NumPy dizisi değil\nplt.title(f'Predicted Class: {predicted_class}')\nplt.axis('off')  # Eksenleri gizle\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T10:16:53.193368Z","iopub.execute_input":"2024-10-24T10:16:53.193731Z","iopub.status.idle":"2024-10-24T10:16:53.683225Z","shell.execute_reply.started":"2024-10-24T10:16:53.193673Z","shell.execute_reply":"2024-10-24T10:16:53.682262Z"},"trusted":true},"execution_count":null,"outputs":[]}]}